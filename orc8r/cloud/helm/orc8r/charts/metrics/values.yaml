# Default values for metrics.
imagePullSecrets: []

metrics:
  # Default volume configurations for metrics data - shared across prometheus,
  # alertmanager, and configmanager pods
  volumes:
    prometheusData:
      volumeSpec: {}
        # hostPath:
        #   path: /prometheusData
        #   type: DirectoryOrCreate
    prometheusConfig:
      volumeSpec: {}
        # hostPath:
        #   path: /configs/prometheus
        #   type: DirectoryOrCreate

prometheus:
  # Enable/Disable chart
  create: true

  # Preconfigure alerts for orchestrator in prometheus
  includeOrc8rAlerts: false

  prometheusCacheHostname: "orc8r-prometheus-cache"
  alertmanagerHostname: "orc8r-alertmanager"

  replicas: 1

  # Set to 1 if using a minikube setup
  useMinikube:

  # Retention configurations for prometheus
  retention:
    time: 30d

  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: prometheus
        port: 9090
        targetPort: 9090

  image:
    repository: docker.io/prom/prometheus
    tag: v2.12.0
    pullPolicy: IfNotPresent

  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

  customAlerts: []

alertmanager:
  # Enable/Disable chart
  create: true

  replicas: 1

  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: alertmanager
        port: 9093
        targetPort: 9093

  image:
    repository: docker.io/prom/alertmanager
    tag: v0.18.0
    pullPolicy: IfNotPresent

  resources: {}
  nodeSelector: {}
  tolerations: []
  # Pod affinity must be used to ensure that this pod runs on same node as prometheus
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - prometheus
          topologyKey: "kubernetes.io/hostname"

prometheusConfigurer:
  # Enable/Disable chart
  create: true

  replicas: 1

  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: prom-configmanager
        port: 9100
        targetPort: 9100

  prometheusConfigurerPort: 9100
  rulesDir: "/etc/configs/alert_rules"
  prometheusURL: "orc8r-prometheus:9090"

  image:
    repository:
    tag:
    pullPolicy: IfNotPresent

  resources: {}
  nodeSelector: {}
  tolerations: []
  # Pod affinity must be used to ensure that this pod runs on same node as prometheus
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - prometheus
          topologyKey: "kubernetes.io/hostname"

alertmanagerConfigurer:
  # Enable/Disable chart
  create: true

  replicas: 1

  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: alertmanager-config
        port: 9101
        targetPort: 9101

  alertmanagerConfigPort: 9101
  alertmanagerConfPath: "/etc/configs/alertmanager.yml"
  alertmanagerURL: "orc8r-alertmanager:9093"

  image:
    repository:
    tag:
    pullPolicy: IfNotPresent

  resources: {}
  nodeSelector: {}
  tolerations: []
  # Pod affinity must be used to ensure that this pod runs on same node as prometheus
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - prometheus
          topologyKey: "kubernetes.io/hostname"

prometheusCache:
  # Enable/Disable chart
  create: true
  # Service configuration.
  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: prometheus-cache
        port: 9091
        targetPort: 9091

  image:
    repository:
    tag:
    pullPolicy: IfNotPresent

  # Maximum number of datapoints in the cache at one time. Unlimited if <= 0.
  limit: 0

  # Number of metrics replicas desired
  replicas: 1

  # Resource limits & requests
  resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Define which Nodes the Pods are scheduled on.
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # Tolerations for use with node taints
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # Assign prometheusCache to run on specific nodes
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

grafana:
  # Enable/Disable chart
  create: true
  # Service configuration.
  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: grafana
        port: 3000
        targetPort: 3000

  environment:
    prometheusHost: "orc8r-prometheus"
    prometheusPort: "9090"

  volumes:
    # Default volume configurations for grafana data.
    grafanaData:
      volumeSpec:
        emptyDir: {}

  image:
    repository:
    tag:
    pullPolicy: IfNotPresent

  # Number of metrics replicas desired
  replicas: 1

  # Resource limits & requests
  resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Define which Nodes the Pods are scheduled on.
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # Tolerations for use with node taints
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # Assign grafana to run on specific nodes
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

userGrafana:
  # Enable/Disable chart
  create: true

  # Reverse proxy setting, root url grafana will be accessed through
  rootURL: /grafana

  # Service configuration.
  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    ports:
      - name: grafana
        port: 3000
        targetPort: 3000

  volumes:
    # Default volume configurations for grafana data.
    dashboards: {}
    datasources: {}
    dashboardproviders: {}
    grafanaData: {}

  image:
    repository: grafana/grafana
    tag: 6.6.2
    pullPolicy: IfNotPresent

  # Number of metrics replicas desired
  replicas: 1

  # Resource limits & requests
  # These defaults are suggested as lower limits may cause grafana to crashloop
  resources:
    limits:
      cpu: 500m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 1024Mi

  # Define which Nodes the Pods are scheduled on.
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # Tolerations for use with node taints
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # Assign grafana to run on specific nodes
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

configFiles:
  useDefaults:
    alertmanagerConf: true
    internalAlertsConf: true

# can be used to add new config or overwrite the default config files completely after the configFiles default has been disabled
extraConfigFiles:
